{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import nltk\n",
    "import string\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import mlflow\n",
    "from sklearnex import patch_sklearn\n",
    "from warnings import filterwarnings\n",
    "patch_sklearn()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:16:54.078736Z",
     "start_time": "2025-03-11T15:16:54.075494Z"
    }
   },
   "cell_type": "code",
   "source": "filterwarnings(\"ignore\")",
   "id": "1c721c30c36593c8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:17:02.439500Z",
     "start_time": "2025-03-11T15:16:54.260176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ag_news_dataset = load_dataset(\"ag_news\")\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ],
   "id": "a3cbdf79a881bddc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ĞÑƒĞ¶Ğ½Ğ¾: (Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾, Ğ¡Ñ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³, Ğ›ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ) * (binary, count, tf-idf)) -> F1_Macro",
   "id": "f71aa47e94a2e150"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:17:02.448309Z",
     "start_time": "2025-03-11T15:17:02.445394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_preprocess_types = [None, 'ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³', 'Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ']\n",
    "#words_classes = ['N', 'NJ', 'NJV', 'ALL']\n",
    "words_classes = ['NJ', 'NJV', 'ALL']\n",
    "\n",
    "#frequency_filtration_types = [None, 'low', 'high', 'both']\n",
    "frequency_filtration_types = [None]\n",
    "\n",
    "vector_representation_types = ['binary', 'count', 'tfidf']"
   ],
   "id": "e43dd05f283d82ff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:17:07.112524Z",
     "start_time": "2025-03-11T15:17:07.108464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iterations_num = len(text_preprocess_types) * len(words_classes) * len(frequency_filtration_types)\n",
    "print(iterations_num)"
   ],
   "id": "5061d583c06cdce6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:17:12.341539Z",
     "start_time": "2025-03-11T15:17:12.337918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def base_ag_news_preprocess(text):\n",
    "    tokens = text.lower()\n",
    "\n",
    "    # Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¿ĞµÑ† ÑĞ»Ğ¾Ğ²\n",
    "    special_words = ['reuters', 'afp', 'ap', 'usatoday.com', 'forbes.com', 'target=/stocks/quickinfo/fullquote\"' ]\n",
    "    for word in special_words:\n",
    "        tokens = tokens.replace(word, '')\n",
    "    \n",
    "    pattern = r'[&lt][^<>]*&gt'\n",
    "    tokens = re.sub(pattern, '', tokens)\n",
    "    \n",
    "    # Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿ÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ğ¸ Ğ¸ Ñ†Ğ¸Ñ„Ñ€\n",
    "    #tokens = ''.join(i if i not in set(string.punctuation) - set('-') | set(string.digits) else ' ' for i in tokens)\n",
    "    tokens = ''.join(i if i not in set(string.punctuation)  | set(string.digits) else ' ' for i in tokens)\n",
    "    \n",
    "    # Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\n",
    "    tokens = nltk.word_tokenize(tokens)\n",
    "    \n",
    "    # Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ¾Ğ¿ ÑĞ»Ğ¾Ğ²\n",
    "    #stop_wordsL = stop_words - {'no','not'}\n",
    "    stop_wordsL = stop_words\n",
    "    tokens = [word for word in tokens if (word not in stop_wordsL and word != '-')]\n",
    "    return tokens"
   ],
   "id": "c4de3f20c57a02f9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:17:12.756875Z",
     "start_time": "2025-03-11T15:17:12.752060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def different_ag_news_preprocess(tokens, preprocess_type, words_class):\n",
    "    \n",
    "    # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ»Ğ¾Ğ²\n",
    "    if preprocess_type == 'Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ':\n",
    "        lemmatizer = nltk.WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    elif preprocess_type == 'ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³':\n",
    "        stemmer = nltk.PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ñ€ĞµÑ‡Ğ¸\n",
    "    tokens = pos_tag(tokens)\n",
    "    if words_class == 'N':\n",
    "        tokens = [word for word, tag in tokens if tag.startswith('N')]\n",
    "    elif words_class == 'NJ':\n",
    "        tokens = [word for word, tag in tokens if tag.startswith('N') or tag.startswith('J')]\n",
    "    elif words_class == 'NJV':\n",
    "        tokens = [word for word, tag in tokens if tag.startswith('N') or tag.startswith('J') or tag.startswith('V')]\n",
    "    elif words_class == 'ALL':\n",
    "        tokens = [word for word, _ in tokens]\n",
    "    \n",
    "    return tokens  "
   ],
   "id": "4b933f0767b60bc5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:17:13.410765Z",
     "start_time": "2025-03-11T15:17:13.407320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def frequency_filtration(words_dictionary, frequency_filtration_type):\n",
    "    if frequency_filtration_type == 'low':\n",
    "        return dict([(key, value) for key, value in words_dictionary.items() if value >= 10 ])\n",
    "    elif frequency_filtration_type == 'high':\n",
    "        return dict([(key, value) for key, value in words_dictionary.items() if value <= 3000])\n",
    "    elif frequency_filtration_type == 'both':\n",
    "        return dict([(key, value) for key, value in words_dictionary.items() if 10 <= value <= 3000])\n",
    "    else:\n",
    "        return words_dictionary"
   ],
   "id": "46d4699c8beec784",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:17:13.744975Z",
     "start_time": "2025-03-11T15:17:13.741785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dummy(doc):\n",
    "    return doc"
   ],
   "id": "9da65dd9e2d361a2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:10:05.461693Z",
     "start_time": "2025-03-11T21:10:05.445680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def final_ag_news_preprocess(dataset, model_type):\n",
    "    # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…\n",
    "    x_train = dataset['train']['text']\n",
    "    y_train = dataset['train']['label']\n",
    "    \n",
    "    x_test = dataset['test']['text']\n",
    "    y_test = dataset['test']['label']\n",
    "    \n",
    "    # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°\n",
    "    for i, text in enumerate(x_train):\n",
    "        x_train[i] = base_ag_news_preprocess(text)\n",
    "        \n",
    "    for i, text in enumerate(x_test):\n",
    "        x_test[i] = base_ag_news_preprocess(text)\n",
    "    \n",
    "    index = 2\n",
    "    # Ğ’Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°\n",
    "    for preprocess_type in text_preprocess_types: # 3 Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ°\n",
    "        for words_class in words_classes:         # 4 Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ°\n",
    "            words = {}\n",
    "            xtr = x_train\n",
    "            xte = x_test\n",
    "            \n",
    "            # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²\n",
    "            for i, tokens in enumerate(xtr):\n",
    "                final_tokens = different_ag_news_preprocess(tokens, preprocess_type, words_class)\n",
    "                xtr[i] = final_tokens\n",
    "                \n",
    "                # Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ\n",
    "                for token in final_tokens:\n",
    "                    if token not in words:\n",
    "                        words[token] = 1\n",
    "                    else:\n",
    "                        words[token] += 1\n",
    "            \n",
    "            xte = [different_ag_news_preprocess(tokens, preprocess_type, words_class) for tokens in xte]\n",
    "                    \n",
    "            # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğµ\n",
    "            for frequency_filtration_type in frequency_filtration_types: # 4 Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ°\n",
    "                filtered_words = frequency_filtration(words, frequency_filtration_type)\n",
    "                token_length = len(filtered_words)\n",
    "                \n",
    "                # Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ»Ğ¾Ğ²\n",
    "                word_list = sorted(filtered_words.keys())\n",
    "                # ĞŸÑ€Ğ¸ÑĞ²Ğ¾ĞµĞ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ²\n",
    "                words_indexed = {}\n",
    "                for idx, word in enumerate(word_list):\n",
    "                    words_indexed[word] = idx\n",
    "                \n",
    "                # OHE\n",
    "                vectorizer_OHE = CountVectorizer(vocabulary=words_indexed, tokenizer=dummy, preprocessor=dummy, dtype=np.int8, binary=True)\n",
    "                x_train_OHE = vectorizer_OHE.fit_transform(xtr)\n",
    "                x_test_OHE = vectorizer_OHE.transform(xte)\n",
    "                \n",
    "                # COUNT\n",
    "                vectorizer_COUNT = CountVectorizer(vocabulary=words_indexed, tokenizer=dummy, preprocessor=dummy, dtype=np.int8)\n",
    "                x_train_COUNT = vectorizer_COUNT.fit_transform(xtr)\n",
    "                x_test_COUNT = vectorizer_COUNT.transform(xte)\n",
    "                \n",
    "                # TF-IDF\n",
    "                vectorizer_TFIDF = TfidfVectorizer(vocabulary=words_indexed, preprocessor=dummy, tokenizer=dummy, dtype=np.float32)\n",
    "                x_train_TFIDF = vectorizer_TFIDF.fit_transform(xtr)\n",
    "                x_test_TFIDF = vectorizer_TFIDF.transform(xte)\n",
    "\n",
    "                # ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ²\n",
    "                if model_type == 'DT':\n",
    "                    clf_OHE = DecisionTreeClassifier()\n",
    "                    clf_COUNT = DecisionTreeClassifier()\n",
    "                    clf_TFIDF = DecisionTreeClassifier()\n",
    "                elif model_type == 'RF':\n",
    "                    clf_OHE = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "                    clf_COUNT = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "                    clf_TFIDF = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "                elif model_type == 'ADA':\n",
    "                    clf_OHE =  AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=12, max_depth=25, n_jobs=-1), n_estimators=50, learning_rate=0.3)\n",
    "                    clf_COUNT =  AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=12, max_depth=25, n_jobs=-1), n_estimators=50, learning_rate=0.3)\n",
    "                    clf_TFIDF =  AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=12, max_depth=25, n_jobs=-1), n_estimators=50, learning_rate=0.3)\n",
    "                \n",
    "                # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ²\n",
    "                clf_OHE = clf_OHE.fit(x_train_OHE, y_train)\n",
    "                clf_COUNT = clf_COUNT.fit(x_train_COUNT, y_train)\n",
    "                clf_TFIDF = clf_TFIDF.fit(x_train_TFIDF, y_train)\n",
    "                \n",
    "                # Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ\n",
    "                predictions_OHE = clf_OHE.predict(x_test_OHE)\n",
    "                predictions_COUNT = clf_COUNT.predict(x_test_COUNT)\n",
    "                predictions_TFIDF = clf_TFIDF.predict(x_test_TFIDF)\n",
    "                \n",
    "                # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸\n",
    "                macro_score_OHE = f1_score(y_test, predictions_OHE, average='macro')\n",
    "                macro_score_COUNT = f1_score(y_test, predictions_COUNT, average='macro')\n",
    "                macro_score_TFIDF = f1_score(y_test, predictions_TFIDF, average='macro')\n",
    "                \n",
    "                mlflow.start_run(run_name=f'{model_type}_{preprocess_type}_{words_class}_{frequency_filtration_type}_OHE')\n",
    "                mlflow.log_param('model', clf_OHE.__class__.__name__)\n",
    "                mlflow.log_param('preprocess_type', preprocess_type)\n",
    "                mlflow.log_param('words_class', words_class)\n",
    "                mlflow.log_param('frequency_filtration_type', frequency_filtration_type)\n",
    "                mlflow.log_param('token_length', token_length)\n",
    "                mlflow.sklearn.log_model(clf_OHE, 'DecisionTreeClassifier')\n",
    "                mlflow.log_metric('macro_score', macro_score_OHE)\n",
    "                mlflow.end_run()\n",
    "                \n",
    "                mlflow.start_run(run_name=f'{model_type}_{preprocess_type}_{words_class}_{frequency_filtration_type}_COUNT')\n",
    "                mlflow.log_param('model', clf_COUNT.__class__.__name__)\n",
    "                mlflow.log_param('preprocess_type', preprocess_type)\n",
    "                mlflow.log_param('words_class', words_class)\n",
    "                mlflow.log_param('frequency_filtration_type', frequency_filtration_type)\n",
    "                mlflow.log_param('token_length', token_length)\n",
    "                mlflow.sklearn.log_model(clf_COUNT, 'DecisionTreeClassifier')\n",
    "                mlflow.log_metric('macro_score', macro_score_COUNT)\n",
    "                mlflow.end_run()\n",
    "                \n",
    "                mlflow.start_run(run_name=f'{model_type}_{preprocess_type}_{words_class}_{frequency_filtration_type}_TFIDF')\n",
    "                mlflow.log_param('model', clf_TFIDF.__class__.__name__)\n",
    "                mlflow.log_param('preprocess_type', preprocess_type)\n",
    "                mlflow.log_param('words_class', words_class)\n",
    "                mlflow.log_param('frequency_filtration_type', frequency_filtration_type)\n",
    "                mlflow.log_param('token_length', token_length)\n",
    "                mlflow.sklearn.log_model(clf_TFIDF, 'DecisionTreeClassifier')\n",
    "                mlflow.log_metric('macro_score', macro_score_TFIDF)\n",
    "                mlflow.end_run()\n",
    "                \n",
    "                index += 1\n",
    "                print(f'Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ {index} / {iterations_num}')"
   ],
   "id": "660b6dd207e48d59",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T13:21:57.437670Z",
     "start_time": "2025-03-11T13:21:57.420568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_run(dataset, preprocess_type, words_class, frequency_filtration_type, model_type):\n",
    "    # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…\n",
    "    x_train = dataset['train']['text']\n",
    "    y_train = dataset['train']['label']\n",
    "    \n",
    "    x_test = dataset['test']['text']\n",
    "    y_test = dataset['test']['label']\n",
    "    \n",
    "    # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°\n",
    "    for i, text in enumerate(x_train):\n",
    "        x_train[i] = base_ag_news_preprocess(text)\n",
    "        \n",
    "    for i, text in enumerate(x_test):\n",
    "        x_test[i] = base_ag_news_preprocess(text)\n",
    "    \n",
    "    words = {}\n",
    "    xtr = x_train\n",
    "    xte = x_test\n",
    "            \n",
    "    # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²\n",
    "    for i, tokens in enumerate(xtr):\n",
    "        final_tokens = different_ag_news_preprocess(tokens, preprocess_type, words_class)\n",
    "        xtr[i] = final_tokens\n",
    "                \n",
    "        # Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ\n",
    "        for token in final_tokens:\n",
    "            if token not in words:\n",
    "                words[token] = 1\n",
    "            else:\n",
    "                words[token] += 1\n",
    "            \n",
    "    xte = [different_ag_news_preprocess(tokens, preprocess_type, words_class) for tokens in xte]\n",
    "                    \n",
    "    # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğµ\n",
    "    filtered_words = frequency_filtration(words, frequency_filtration_type)\n",
    "    token_length = len(filtered_words)\n",
    "                \n",
    "    # Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ»Ğ¾Ğ²\n",
    "    word_list = sorted(filtered_words.keys())\n",
    "    # ĞŸÑ€Ğ¸ÑĞ²Ğ¾ĞµĞ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ²\n",
    "    words_indexed = {}\n",
    "    for idx, word in enumerate(word_list):\n",
    "        words_indexed[word] = idx\n",
    "        \n",
    "    # OHE\n",
    "    vectorizer_OHE = CountVectorizer(vocabulary=words_indexed, tokenizer=dummy, preprocessor=dummy, dtype=np.int8, binary=True)\n",
    "    x_train_OHE = vectorizer_OHE.fit_transform(xtr)\n",
    "    x_test_OHE = vectorizer_OHE.transform(xte)\n",
    "                \n",
    "    # COUNT\n",
    "    vectorizer_COUNT = CountVectorizer(vocabulary=words_indexed, tokenizer=dummy, preprocessor=dummy, dtype=np.int8)\n",
    "    x_train_COUNT = vectorizer_COUNT.fit_transform(xtr)\n",
    "    x_test_COUNT = vectorizer_COUNT.transform(xte)\n",
    "                \n",
    "    # TF-IDF\n",
    "    vectorizer_TFIDF = TfidfVectorizer(vocabulary=words_indexed, preprocessor=dummy, tokenizer=dummy, dtype=np.float32)\n",
    "    x_train_TFIDF = vectorizer_TFIDF.fit_transform(xtr)\n",
    "    x_test_TFIDF = vectorizer_TFIDF.transform(xte)\n",
    "    \n",
    "    # ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ²\n",
    "    if model_type == 'DT':\n",
    "        clf_OHE = DecisionTreeClassifier()\n",
    "        clf_COUNT = DecisionTreeClassifier()\n",
    "        clf_TFIDF = DecisionTreeClassifier()\n",
    "    elif model_type == 'RF':\n",
    "        clf_OHE = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "        clf_COUNT = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "        clf_TFIDF = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "    \n",
    "    # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ²\n",
    "    clf_OHE = clf_OHE.fit(x_train_OHE, y_train)\n",
    "    clf_COUNT = clf_COUNT.fit(x_train_COUNT, y_train)\n",
    "    clf_TFIDF = clf_TFIDF.fit(x_train_TFIDF, y_train)\n",
    "                \n",
    "    # Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ\n",
    "    predictions_OHE = clf_OHE.predict(x_test_OHE)\n",
    "    predictions_COUNT = clf_COUNT.predict(x_test_COUNT)\n",
    "    predictions_TFIDF = clf_TFIDF.predict(x_test_TFIDF)\n",
    "                \n",
    "    # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸\n",
    "    macro_score_OHE = f1_score(y_test, predictions_OHE, average='macro')\n",
    "    macro_score_COUNT = f1_score(y_test, predictions_COUNT, average='macro')\n",
    "    macro_score_TFIDF = f1_score(y_test, predictions_TFIDF, average='macro')\n",
    "    \n",
    "    mlflow.start_run(run_name=f'test_{preprocess_type}_{words_class}_{frequency_filtration_type}_OHE')\n",
    "    mlflow.log_param('model', clf_OHE.__class__.__name__)\n",
    "    mlflow.log_param('tree_depth', clf_OHE.get_depth())\n",
    "    mlflow.log_param('preprocess_type', preprocess_type)\n",
    "    mlflow.log_param('words_class', words_class)\n",
    "    mlflow.log_param('frequency_filtration_type', frequency_filtration_type)\n",
    "    mlflow.log_param('token_length', token_length)\n",
    "    mlflow.sklearn.log_model(clf_OHE, 'DecisionTreeClassifier')\n",
    "    mlflow.log_metric('macro_score', macro_score_OHE)\n",
    "    mlflow.end_run()\n",
    "    \n",
    "    mlflow.start_run(run_name=f'test_{preprocess_type}_{words_class}_{frequency_filtration_type}_COUNT')\n",
    "    mlflow.log_param('model', clf_COUNT.__class__.__name__)\n",
    "    mlflow.log_param('tree_depth', clf_TFIDF.get_depth())\n",
    "    mlflow.log_param('preprocess_type', preprocess_type)\n",
    "    mlflow.log_param('words_class', words_class)\n",
    "    mlflow.log_param('frequency_filtration_type', frequency_filtration_type)\n",
    "    mlflow.log_param('token_length', token_length)\n",
    "    mlflow.sklearn.log_model(clf_COUNT, 'DecisionTreeClassifier')\n",
    "    mlflow.log_metric('macro_score', macro_score_COUNT)\n",
    "    mlflow.end_run()\n",
    "    \n",
    "    mlflow.start_run(run_name=f'test_{preprocess_type}_{words_class}_{frequency_filtration_type}_TFIDF')\n",
    "    mlflow.log_param('model', clf_TFIDF.__class__.__name__)\n",
    "    mlflow.log_param('tree_depth', clf_TFIDF.get_depth())\n",
    "    mlflow.log_param('preprocess_type', preprocess_type)\n",
    "    mlflow.log_param('words_class', words_class)\n",
    "    mlflow.log_param('frequency_filtration_type', frequency_filtration_type)\n",
    "    mlflow.log_param('token_length', token_length)\n",
    "    mlflow.sklearn.log_model(clf_TFIDF, 'DecisionTreeClassifier')\n",
    "    mlflow.log_metric('macro_score', macro_score_TFIDF)\n",
    "    mlflow.end_run()\n",
    "    "
   ],
   "id": "356187a9d739b4bd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:10:31.654302Z",
     "start_time": "2025-03-11T21:10:31.586646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(experiment_name=\"agNewsADA\")"
   ],
   "id": "3aa85a435033448",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:10:31 INFO mlflow.tracking.fluent: Experiment with name 'agNewsADA' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/793654491394688587', creation_time=1741727431630, experiment_id='793654491394688587', last_update_time=1741727431630, lifecycle_stage='active', name='agNewsADA', tags={}>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:51:08.237688Z",
     "start_time": "2025-03-11T21:10:49.212695Z"
    }
   },
   "cell_type": "code",
   "source": "final_ag_news_preprocess(ag_news_dataset, model_type='ADA')",
   "id": "d127817ddf38f7b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:14:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_N_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/2f9f6fa7205b4302bafd231eb383eb56\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:14:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_N_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/ec6294b3c04c46d2ac594ce3b832cc5d\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:14:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_N_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/9c0733dc616d4630844eb12fa3b37fdf\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 3 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:15:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_N_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/9c7e4d7fec274f929cd6ed2e0219d865\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:15:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_N_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/7caf2601c201439da7f761f23e107801\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:15:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_N_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/23d71cd0da82418c9cbe69fd642ec542\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 4 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:17:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJ_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/802d0353191e41b39aab4b34b169c318\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:17:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJ_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/dd3848289984405cb180bf98c2735d29\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:17:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJ_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/ea69445e48994e15a3c9d6192f09af82\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 5 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:19:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJ_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/26dd64ba75544d12a7abd6ec6d583f1e\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:19:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJ_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/b7979e4db2e649b4bd04ff76ee6ef252\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:19:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJ_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/b2e2ee2190f249c1b2dbc2f5a49881dc\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 6 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:21:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJV_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/084cd3785fb041b28bacc6b0528613a9\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:21:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJV_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/c08d774cb8af44d0ae7547a2ce2fcad9\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:21:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJV_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/fae72237056641d4b36ded1db04667ab\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 7 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:22:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJV_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/fa1bb6a43f3342f484203f1070bdc299\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:22:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJV_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/2798134494094a2888ff42ced64a1c61\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:22:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_NJV_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/c7f6131001b848fd9c2262dee583ec1e\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 8 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:24:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_ALL_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/a403402143564422bbbb74375e19c583\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:24:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_ALL_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/9322e06559094478bcaa0db5f6233606\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:24:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_ALL_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/0fff36a3664341c3a062e6c32d5ccca3\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 9 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:26:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_ALL_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/2510a3fc87e04bacb19bcf3283e5cc1e\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:26:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_ALL_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/efcf3bff68cb4b6d8479531ac1c9c668\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:26:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_None_ALL_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/77777c300f4a4b0b914506657f17cf7d\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 10 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:28:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_N_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/91b068c92b534931a63e27b414b24098\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:28:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_N_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/1ef5bcf520b646a290d72e69a6dbdaaa\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:28:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_N_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/9d846df31b894f0ea2cd548ebad31406\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 11 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:29:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_N_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/a98c601d6add445586f1abbdece53b1f\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:29:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_N_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/ccdfb3ef28e04bd68d10fa5fe1766052\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:29:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_N_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/819cda4d0ea14750a2d5413e10dc41f4\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 12 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:31:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJ_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/403fb031d8f040069fe825dc2f91ea07\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:31:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJ_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/678e2e20ad96487ebe1d0ff30927eebb\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:31:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJ_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/43e1dc8bef17452e83bb42d6450832f1\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 13 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:32:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJ_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/37dd6eb846e34ff4a3d26a793b174976\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:32:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJ_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/7dc2984a53dd466eacab5c1c027415d6\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:33:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJ_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/6c291ce385574ae09d4eba291da5a896\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 14 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:35:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJV_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/622498ff51a9404982fc4711ca99391a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:35:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJV_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/58dbc6ca8bb64431a83bcbf55903e69f\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:35:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJV_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/2451314ae85948c9b8554f8ca7692d71\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 15 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:36:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJV_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/dc7bbf0c81db4ca88d276d715d19b442\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:36:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJV_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/c911e131b4134142bb27ea7e26a63449\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:36:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_NJV_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/94bd8e174ed046dbbc923efd2c253736\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 16 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:38:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_ALL_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/2a11d27eb4fe4f529043bce2fa0cabd6\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:38:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_ALL_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/84f90be712f4483abcb69c073c303911\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:38:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_ALL_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/b4a36391369e418694724e82075b48c3\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 17 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:39:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_ALL_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/54d091dac38b43229a43f0f9c0f10e55\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:39:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_ALL_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/2356fa1e025c487d87e85d18666e0926\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:39:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³_ALL_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/172cf01416fa40a982d0bd91c524add0\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 18 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:41:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_N_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/597d31e5cc4547f0b5a459a96eb7d158\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:41:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_N_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/3a016c3fc3d54154a90ddafe2e1b11ce\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:41:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_N_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/aa13ebc1b42e4fdbafb0c010a0baa395\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 19 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:42:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_N_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/0aa067f71167451197f61426c6d72451\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:42:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_N_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/66b2eda4bc85451ebf382df8dc16ac0c\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:42:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_N_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/6bb32740b0484d258479fcfa9a702c75\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 20 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:44:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJ_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/0b349b622ba046ffb18b0f8d5092d92e\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:44:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJ_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/8b2f9bc15c48434dad5de6c87618c334\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:44:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJ_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/27ecd5c9afbc45099cec89ef7c551993\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 21 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:45:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJ_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/a50c04fcd394427c9451e4e30ee3d90e\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:45:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJ_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/6950eace46eb4c1bb4574e6f56f8c89a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:45:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJ_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/3a01abf5f19641dca25598c962256f4a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 22 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:47:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJV_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/eaaa668022f149aa9082fe4349b07b2d\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:47:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJV_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/9e802cbd2ad84f8d9e06de75df983391\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:47:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJV_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/878e2c140dba48d798da5c15f67696db\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 23 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:48:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJV_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/edaa3041328f49da86018c0e7030c7d8\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:48:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJV_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/3db149e7c62b407f98008f1a6dfdb152\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:48:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJV_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/13834928ee64497c86d3e9c7ac96af58\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 24 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:49:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_ALL_None_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/1f693c8b55464a6ab7d9788ff20ed2ab\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:49:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_ALL_None_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/485197ffc05849ed8e54af80bbb74fef\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:50:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_ALL_None_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/24a1351c781747ed9a8f7edd53531d73\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 25 / 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:50:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_ALL_low_OHE at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/103cc6a184484693bbfbcd7aaf57a018\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:51:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_ALL_low_COUNT at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/1873838f0ce74569a3186c5ee45539e3\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 00:51:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ADA_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_ALL_low_TFIDF at: http://127.0.0.1:5000/#/experiments/793654491394688587/runs/75580dcd2a114361921b0faaebbcd608\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/793654491394688587\n",
      "Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ 26 / 24\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T13:29:02.830506Z",
     "start_time": "2025-03-11T13:23:42.837385Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/11 16:28:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run test_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJ_low_OHE at: http://127.0.0.1:5000/#/experiments/537408113752698407/runs/23ea94598c4143bfb298c45c0cf0974a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/537408113752698407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/11 16:28:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run test_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJ_low_COUNT at: http://127.0.0.1:5000/#/experiments/537408113752698407/runs/9198223fdacc4638acea6f8344de3f75\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/537408113752698407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/11 16:29:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run test_Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ_NJ_low_TFIDF at: http://127.0.0.1:5000/#/experiments/537408113752698407/runs/4b6ae5d8cddc46358b79466b1a52e854\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/537408113752698407\n"
     ]
    }
   ],
   "execution_count": 13,
   "source": "one_run(ag_news_dataset, 'Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ', 'NJ', 'low', 'RF')",
   "id": "7e2889f5c696e2af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T20:52:13.948573Z",
     "start_time": "2025-03-10T20:52:13.945574Z"
    }
   },
   "cell_type": "code",
   "source": "cc = DecisionTreeClassifier()",
   "id": "488d299b7a4c3fb",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T19:48:36.328004Z",
     "start_time": "2025-03-11T19:46:01.378840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = ag_news_dataset\n",
    "preprocess_type = 'Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ'\n",
    "words_class = 'NJ'\n",
    "frequency_filtration_type = 'low'\n",
    "\n",
    "# ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…\n",
    "x_train = dataset['train']['text']\n",
    "y_train = dataset['train']['label']\n",
    "    \n",
    "x_test = dataset['test']['text']\n",
    "y_test = dataset['test']['label']\n",
    "    \n",
    "# Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°\n",
    "for i, text in enumerate(x_train):\n",
    "    x_train[i] = base_ag_news_preprocess(text)\n",
    "        \n",
    "for i, text in enumerate(x_test):\n",
    "    x_test[i] = base_ag_news_preprocess(text)\n",
    "    \n",
    "words = {}\n",
    "xtr = x_train\n",
    "xte = x_test\n",
    "            \n",
    "# ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²\n",
    "for i, tokens in enumerate(xtr):\n",
    "    final_tokens = different_ag_news_preprocess(tokens, preprocess_type, words_class)\n",
    "    xtr[i] = final_tokens\n",
    "                \n",
    "    # Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ\n",
    "    for token in final_tokens:\n",
    "        if token not in words:\n",
    "            words[token] = 1\n",
    "        else:\n",
    "            words[token] += 1\n",
    "            \n",
    "xte = [different_ag_news_preprocess(tokens, preprocess_type, words_class) for tokens in xte]\n",
    "                    \n",
    "# Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğµ\n",
    "filtered_words = frequency_filtration(words, frequency_filtration_type)\n",
    "token_length = len(filtered_words)\n",
    "                \n",
    "# Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ»Ğ¾Ğ²\n",
    "word_list = sorted(filtered_words.keys())\n",
    "# ĞŸÑ€Ğ¸ÑĞ²Ğ¾ĞµĞ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ²\n",
    "words_indexed = {}\n",
    "for idx, word in enumerate(word_list):\n",
    "    words_indexed[word] = idx\n",
    "    \n",
    "# OHE\n",
    "vectorizer_OHE = CountVectorizer(vocabulary=words_indexed, tokenizer=dummy, preprocessor=dummy, dtype=np.int8, binary=True)\n",
    "x_train_OHE = vectorizer_OHE.fit_transform(xtr)\n",
    "x_test_OHE = vectorizer_OHE.transform(xte)\n",
    "            \n",
    "# COUNT\n",
    "vectorizer_COUNT = CountVectorizer(vocabulary=words_indexed, tokenizer=dummy, preprocessor=dummy, dtype=np.int8)\n",
    "x_train_COUNT = vectorizer_COUNT.fit_transform(xtr)\n",
    "x_test_COUNT = vectorizer_COUNT.transform(xte)\n",
    "            \n",
    "# TF-IDF\n",
    "vectorizer_TFIDF = TfidfVectorizer(vocabulary=words_indexed, preprocessor=dummy, tokenizer=dummy, dtype=np.float32)\n",
    "x_train_TFIDF = vectorizer_TFIDF.fit_transform(xtr)\n",
    "x_test_TFIDF = vectorizer_TFIDF.transform(xte)"
   ],
   "id": "f8ebf9b51009ab3b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:35:04.986578Z",
     "start_time": "2025-03-11T14:34:35.266864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf_OHE = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "clf_OHE = clf_OHE.fit(x_train_OHE, y_train)"
   ],
   "id": "ead27b1f895e7b07",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:35:07.931201Z",
     "start_time": "2025-03-11T14:35:07.876599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_OHE = clf_OHE.predict(x_test_OHE)\n",
    "macro_score_OHE = f1_score(y_test, predictions_OHE, average='macro')"
   ],
   "id": "9a32753c76fee33",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:35:09.132790Z",
     "start_time": "2025-03-11T14:35:09.129164Z"
    }
   },
   "cell_type": "code",
   "source": "print(macro_score_OHE)",
   "id": "7f1bb1652b7a6ad9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8811401647147361\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:20:18.000064Z",
     "start_time": "2025-03-11T15:20:17.996919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf_COUNT = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "#clf_COUNT = clf_COUNT.fit(x_train_COUNT, y_train)"
   ],
   "id": "615418eb24d06ed6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:38:05.316804Z",
     "start_time": "2025-03-11T14:38:05.258759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_COUNT = clf_COUNT.predict(x_test_OHE)\n",
    "macro_score_COUNT = f1_score(y_test, predictions_COUNT, average='macro')"
   ],
   "id": "10f85fd99fae60c6",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:38:06.420221Z",
     "start_time": "2025-03-11T14:38:06.417415Z"
    }
   },
   "cell_type": "code",
   "source": "print(macro_score_COUNT)",
   "id": "f35908b8befb5d35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8793384460507578\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:39:15.599507Z",
     "start_time": "2025-03-11T14:38:48.295663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf_TFIDF = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "clf_TFIDF = clf_TFIDF.fit(x_train_TFIDF, y_train)"
   ],
   "id": "dae2fdb7ef004750",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:39:28.895743Z",
     "start_time": "2025-03-11T14:39:28.838718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_TFIDF = clf_TFIDF.predict(x_test_TFIDF)\n",
    "macro_score_TFIDF = f1_score(y_test, predictions_TFIDF, average='macro')"
   ],
   "id": "31f28f4f206c1fdc",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:45:21.724126Z",
     "start_time": "2025-03-11T14:45:21.721087Z"
    }
   },
   "cell_type": "code",
   "source": "print(macro_score_TFIDF)",
   "id": "f12b7a39ddc8ec94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8800442265813493\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T20:20:38.351570Z",
     "start_time": "2025-03-11T20:19:21.439227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf_OHE_GB = GradientBoostingClassifier()\n",
    "clf_OHE_GB = clf_OHE_GB.fit(x_train_OHE, y_train)"
   ],
   "id": "d1d995f525bcc89a",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T20:20:40.907320Z",
     "start_time": "2025-03-11T20:20:40.877164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_GB_OHE = clf_OHE_GB.predict(x_test_OHE)\n",
    "macro_score_OHE_GB = f1_score(y_test, predictions_GB_OHE, average='macro')"
   ],
   "id": "8472e8a82bbb934d",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T20:20:42.226203Z",
     "start_time": "2025-03-11T20:20:42.221710Z"
    }
   },
   "cell_type": "code",
   "source": "print(macro_score_OHE_GB)",
   "id": "b7d495a09653bb57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8202423408128906\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:07:14.167990Z",
     "start_time": "2025-03-11T21:06:50.599939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf_OHE_ADA = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=12, max_depth=25, n_jobs=-1), n_estimators=50, learning_rate=0.3)\n",
    "clf_OHE_ADA = clf_OHE_ADA.fit(x_train_OHE, y_train)"
   ],
   "id": "a2e8169ffbf98d2e",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:07:15.924096Z",
     "start_time": "2025-03-11T21:07:15.163345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_ADA_OHE = clf_OHE_ADA.predict(x_test_OHE)\n",
    "macro_score_ADA_OHE = f1_score(y_test, predictions_ADA_OHE, average='macro')"
   ],
   "id": "3052665e5de5ca69",
   "outputs": [],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:07:16.949890Z",
     "start_time": "2025-03-11T21:07:16.946520Z"
    }
   },
   "cell_type": "code",
   "source": "print(macro_score_ADA_OHE)",
   "id": "6fc30eaa5048f6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8810723137667106\n"
     ]
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:06:47.888494Z",
     "start_time": "2025-03-11T21:06:10.826511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf_COUNT_ADA = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=12, max_depth=25, n_jobs=-1), n_estimators=50, learning_rate=0.3)\n",
    "clf_COUNT_ADA = clf_OHE_ADA.fit(x_train_COUNT, y_train)"
   ],
   "id": "1438c82e8b12b1c7",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:06:48.611573Z",
     "start_time": "2025-03-11T21:06:47.894478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_ADA_COUNT = clf_COUNT_ADA.predict(x_test_COUNT)\n",
    "macro_score_ADA_COUNT = f1_score(y_test, predictions_ADA_COUNT, average='macro')"
   ],
   "id": "8f30fb3a2c979b39",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:06:49.603917Z",
     "start_time": "2025-03-11T21:06:49.600539Z"
    }
   },
   "cell_type": "code",
   "source": "print(macro_score_ADA_COUNT)",
   "id": "b78ba8acc1d53066",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8812967726235373\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:04:32.899913Z",
     "start_time": "2025-03-11T21:04:04.594238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf_TFIDF_ADA = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=12, max_depth=25, n_jobs=-1), n_estimators=50, learning_rate=0.3)\n",
    "clf_TFIDF_ADA = clf_OHE_ADA.fit(x_train_TFIDF, y_train)"
   ],
   "id": "507c6b3ac751befb",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:04:33.609972Z",
     "start_time": "2025-03-11T21:04:32.902912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_ADA_TFIDF = clf_TFIDF_ADA.predict(x_test_TFIDF)\n",
    "macro_score_ADA_TFIDF = f1_score(y_test, predictions_ADA_TFIDF, average='macro')"
   ],
   "id": "f9f7824a85620f22",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:04:34.601829Z",
     "start_time": "2025-03-11T21:04:34.598830Z"
    }
   },
   "cell_type": "code",
   "source": "print(macro_score_ADA_TFIDF)",
   "id": "97848e42a96d9c33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8857382437564187\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:07:51.634716Z",
     "start_time": "2025-03-11T21:07:51.630605Z"
    }
   },
   "cell_type": "code",
   "source": "clf_OHE_ADA.__class__.__name__",
   "id": "3069a355368ee407",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdaBoostClassifier'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18bac159e0b3f168"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
